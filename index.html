<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="生如逆旅 不止行人">
<meta property="og:type" content="website">
<meta property="og:title" content="Jiayu | Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Jiayu | Blog">
<meta property="og:description" content="生如逆旅 不止行人">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Jiayu | Blog">
<meta name="twitter:description" content="生如逆旅 不止行人">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Jiayu | Blog</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jiayu | Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/9999/12/31/报上名来/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiayu Zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiayu | Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/9999/12/31/报上名来/" itemprop="url">报上名来</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="9999-12-31T23:59:59+08:00">
                9999-12-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/张加语的历史进程/" itemprop="url" rel="index">
                    <span itemprop="name">张加语的历史进程</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="求学经历"><a href="#求学经历" class="headerlink" title="求学经历"></a>求学经历</h1><p>2012-2016 本科 <strong>西北工业大学-航天学院-探测制导与控制技术</strong><br>2016-2019 硕士 <strong>上海交通大学-电子信息与电气工程学院-自动化</strong>  </p>
<h1 id="研究方向"><a href="#研究方向" class="headerlink" title="研究方向"></a>研究方向</h1><p>大数据、机器学习、金融、哲学  </p>
<h1 id="爱好"><a href="#爱好" class="headerlink" title="爱好"></a>爱好</h1><p>乒乓球、网球、羽毛球、游泳、爬山<br>看书、看剧、看电影<br><strong>老友记</strong>重度患者<br>游戏间歇性患者<br><img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fubszmbsgpj31kw23v4qr.jpg" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/17/AI-Tricks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiayu Zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiayu | Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/17/AI-Tricks/" itemprop="url">AI Tricks</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-17T10:24:46+08:00">
                2018-09-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/Ai-Tricks/" itemprop="url" rel="index">
                    <span itemprop="name">Ai Tricks</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h1><p>Dropout是指在为了防止过拟合，在训练过程中按照一定比例对隐层的神经元进行丢弃，测试时要按照（1-p）的概率输出。也可以用于丢弃输入，相当于制造噪声，推荐的对于输入层取0.8，隐层取0.5。<br>本质原理是一种类似bagging的操作，也可以按照进化论的想法解释。</p>
<p>优点是防止了过拟合，缺点是为了达到相同的精度需要更多的时间。</p>
<h1 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h1><p>Batch Normalization是批归一化，它可以解决Inner Covariate Shift的问题，那么ICS问题又是什么呢？它是指在网络前向传播的过程中，数据通过激活函数后分布会发生转变，那么下一层网络就要适应这种转变，不仅耗费时间而且梯度方差会变大，对于某些激活函数不友好<br>使用批归一化之后，每一层的输入都是相同的分布，这也学习时效率变高，而且也在某种程度上避免了梯度爆炸。<br>分训练和测试来说：</p>
<ul>
<li>训练时，首先计算batch数据的均值和方差，然后进行缩放和平移，即可得到新的样本，新样本既保留有原始的数据分布特征，又有归一化可以加速训练，每一轮靠动量学习均值和方差，留待测试时直接使用</li>
<li>测试时，直接使用训练时学到的均值和方差进行归一化</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/16/降维之PCA与LDA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiayu Zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiayu | Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/16/降维之PCA与LDA/" itemprop="url">降维之PCA与LDA</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-16T20:33:54+08:00">
                2018-09-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/降维/" itemprop="url" rel="index">
                    <span itemprop="name">降维</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>降维的两种方法，PCA是非监督，LDA是监督</p>
<h1 id="PCA之一言以蔽之"><a href="#PCA之一言以蔽之" class="headerlink" title="PCA之一言以蔽之"></a>PCA之一言以蔽之</h1><p>PCA的基本想法是将坐标旋转到指定坐标系，然后投影。怎么投影呢，选择投影至特征值较大的方向。具体来说是将原始数据做零均值化之后，计算其协方差矩阵，然后根据特征值大小得到特征向量，在选定的特征向量上进行投影。可保证方差最大，信噪比最大。</p>
<h1 id="LDA之一言以蔽之"><a href="#LDA之一言以蔽之" class="headerlink" title="LDA之一言以蔽之"></a>LDA之一言以蔽之</h1><p>LDA基本想法是将数据投影到一条直线上，在该直线上不同类别之间距离足够远，相同类别之间距离足够近。因类间散度矩阵的秩为(C-1)，C为类别数，导致多分类最终投影类别至多为C-1维。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/16/经典模型之K-means/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiayu Zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiayu | Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/16/经典模型之K-means/" itemprop="url">经典模型之K-means</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-16T14:11:52+08:00">
                2018-09-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/经典模型/" itemprop="url" rel="index">
                    <span itemprop="name">经典模型</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="K-means之一言以蔽之"><a href="#K-means之一言以蔽之" class="headerlink" title="K-means之一言以蔽之"></a>K-means之一言以蔽之</h1><p>K-means是一个经典的无监督聚类方法，输入一堆无标注数据，结果会输出k个类别，使得类别内距离小，类别建距离大</p>
<h2 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">从样本集随机选出k个样本作为初始的均值向量</span><br><span class="line">repeat </span><br><span class="line">    C = []</span><br><span class="line">    计算每个样本与k个均值向量的距离，划进距离最近的簇中，从而得到k个簇</span><br><span class="line">    对k个簇重新计算均值向量并更新</span><br><span class="line">until 所有均值向量均未更新</span><br></pre></td></tr></table></figure>
<h2 id="K-means的优缺点"><a href="#K-means的优缺点" class="headerlink" title="K-means的优缺点"></a>K-means的优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>速度快，可解释性好</li>
<li>主要需要调的参数就是k</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>初始均值向量的选取会对结果和收敛速度产生较大的影响</li>
<li>对噪音和异常点较为敏感</li>
<li>K值得选取不好把握</li>
<li>因为是单点聚类，所以只能发现球状簇</li>
<li>K-means其实做的是一个凸优化，遇到非凸数据就难以收敛</li>
<li>得到的是一个局部最优解，与初始点的选择有关</li>
</ul>
<h2 id="K-means的改进"><a href="#K-means的改进" class="headerlink" title="K-means的改进"></a>K-means的改进</h2><p>计算海量数据时，每次迭代都需要 $样本个数 * 簇的个数$次计算，然而除了初始几次改动比较大之外，后续都是在边缘进行一些微调，浪费了大量的计算，这是一个改进点；另一个则是初始质心的选择</p>
<h3 id="elkan-K-Means"><a href="#elkan-K-Means" class="headerlink" title="elkan K-Means"></a>elkan K-Means</h3><p>针对一个样本点和两个质心，根据三角形两边之和大于第三边、两边之差小于第三边可以少算一个样本至质点的距离，但是对稀疏样本和缺失值情况下这种方法不适用，因为某些距离算法不能计算</p>
<h3 id="mini-batch-K-means"><a href="#mini-batch-K-means" class="headerlink" title="mini-batch K-means"></a>mini-batch K-means</h3><p>此方法每次在全集中有放回地选取一个batch进行更新，速度大大较快，且性能方面差距基本可以忽略。</p>
<h3 id="K-means"><a href="#K-means" class="headerlink" title="K-means++"></a>K-means++</h3><p>这是针对质心选择做出的优化，步骤如下：<br>1：初始化选出一个质心<br>2：计算每个样本与已经选出的质心中最近质心的距离<br>3：选择2中距离最大的样本作为新的质心<br>4：重复2-3步直至选择出k个质心</p>
<h2 id="K-means模型性能度量"><a href="#K-means模型性能度量" class="headerlink" title="K-means模型性能度量"></a>K-means模型性能度量</h2><p>簇间距离大、簇内距离小</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/16/经典模型之KNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiayu Zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiayu | Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/16/经典模型之KNN/" itemprop="url">经典模型之KNN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-16T14:11:45+08:00">
                2018-09-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/经典模型/" itemprop="url" rel="index">
                    <span itemprop="name">经典模型</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="KNN一言以蔽之"><a href="#KNN一言以蔽之" class="headerlink" title="KNN一言以蔽之"></a>KNN一言以蔽之</h1><p>KNN是个很有意思的算法，它无需训练，基本思想是：给定一个样本后，选取样本中离它最近的k个样本进行类别投票或求均值得到输出</p>
<h2 id="KNN优缺点"><a href="#KNN优缺点" class="headerlink" title="KNN优缺点"></a>KNN优缺点</h2><h3 id="KNN优点"><a href="#KNN优点" class="headerlink" title="KNN优点"></a>KNN优点</h3><ul>
<li>原理简单，可解释性好</li>
<li>既可用于分类也可用于回归</li>
<li>训练时间是O(N)</li>
<li>对异常点不敏感，因为是选取最近的几个点进行投票的机制</li>
<li>对数据分布没有假设</li>
</ul>
<h3 id="KNN缺点"><a href="#KNN缺点" class="headerlink" title="KNN缺点"></a>KNN缺点</h3><ul>
<li>计算量大，需要大量的存储资源</li>
<li>样本分布不均衡时结果较差</li>
<li>需要进行数据归一化，否则各个特征值域不同，结果会受到较大的影响</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/16/经典模型之Decision-Tree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiayu Zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiayu | Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/16/经典模型之Decision-Tree/" itemprop="url">经典模型之Decision Tree</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-16T14:11:31+08:00">
                2018-09-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/经典模型/" itemprop="url" rel="index">
                    <span itemprop="name">经典模型</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="决策树一言一概之"><a href="#决策树一言一概之" class="headerlink" title="决策树一言一概之"></a>决策树一言一概之</h1><p>决策树是一个树形结构的模型，是一种if-then规则的集合。训练时根据训练样本生成决策树，其中节点分裂处的特征和属性值视具体模型种类而定，预测时使用训练好的模型进行分类或回归。</p>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>可解释性强</li>
<li>速度快</li>
<li>对于非线性数据不用做数据转换</li>
<li>对缺失值不敏感，缺失值的样本计算属性增益（需要乘上无缺失样本的权重）的时候不参与，确定好分裂后的子节点后，会按照各个子节点的样本数量赋予该缺失样本相应的权重，然后加入至各个子节点。这篇<a href="https://blog.csdn.net/u012328159/article/details/79413610" target="_blank" rel="noopener">博客</a>说得很清晰</li>
<li>在相对短的时间内针对大型数据集可以产生可行且效果良好的解决方案</li>
<li>因为决策树是基于类变量的划分规则去构建分类树，所以会强制地将不同样本分开，所以对类别不均衡的分类样本会有不错的效果</li>
<li>多重共线性不会影响决策树模型，举一个极端的例子：A和B是两个完全相同的特征，使用B判断完之后，A并不会再拿来判断了，定性来说是因为A并不能带来更有效的消息，定量来说因为每一层信息熵不会再因为A而减小<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3></li>
<li>容易过拟合，不过可以辅之以剪枝，同时也是随机森林等bagging方法的切入点</li>
<li>不支持在线学习，来了一个新样本就要重构整个数的结构</li>
<li>忽略了数据之间的相关性，也可以说成是一个优点：不受多重共线性影响</li>
<li>若选用信息增益作为选取特征的标准，则会偏向属性值较多的特征，因此C4.5选用的是增益率，为增益除上每个属性a的“固有值”，但增益率又会对属性值较少的特征有所偏好，故实际中经常采用的是贪心：先选出信息增益高于平均水平的属性，再在其中选择增益率最高的属性。</li>
<li>算法的时间复杂度是log(n)，n为训练样本的个数</li>
<li>决策树是按照贪心算法求解的，并不能得到全局最优解</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/16/经典模型之Naive-Bayes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiayu Zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiayu | Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/16/经典模型之Naive-Bayes/" itemprop="url">经典模型之Naive Bayes</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-16T14:11:18+08:00">
                2018-09-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/经典模型/" itemprop="url" rel="index">
                    <span itemprop="name">经典模型</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Naive-Bayes之一言以概之"><a href="#Naive-Bayes之一言以概之" class="headerlink" title="Naive Bayes之一言以概之"></a>Naive Bayes之一言以概之</h1><p>NB算法直接利用训练样本集的统计特性，在条件独立性假设下使用先验概率和条件概率估计后验概率。<br>$$P(Y|X) = \frac{P(X|Y)P(Y)}{P(X)} \tag{1}$$<br>$$P(X|Y) = \prod_{i=i}^d P(x_i|Y) \tag{2}$$</p>
<h2 id="NB的优点和缺点"><a href="#NB的优点和缺点" class="headerlink" title="NB的优点和缺点"></a>NB的优点和缺点</h2><h3 id="NB的优点"><a href="#NB的优点" class="headerlink" title="NB的优点"></a>NB的优点</h3><ul>
<li>原理明确，可解释性强</li>
<li>适用于增量式在线学习</li>
<li>对缺失数据不算太敏感</li>
</ul>
<h3 id="NB的缺点"><a href="#NB的缺点" class="headerlink" title="NB的缺点"></a>NB的缺点</h3><ul>
<li>作出的条件独立性假设不符合实际运用</li>
<li>对输入数据的表达形式很敏感，比如离散属性可以用个数比来计算条件概率，连续属性需要用概率密度来计算条件概率</li>
<li>需要做拉普拉斯平滑化</li>
<li>先验概率需要依赖一定假设，可能因为假设的原因导致预测效果不佳</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/16/经典模型之SVM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiayu Zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiayu | Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/16/经典模型之SVM/" itemprop="url">经典模型之SVM</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-16T11:35:34+08:00">
                2018-09-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/经典模型/" itemprop="url" rel="index">
                    <span itemprop="name">经典模型</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作为理论完备的经典机器学习方法，SVM曾被认为是最佳分类器，在这里便浅谈SVM相关原理及特性。</p>
<h1 id="SVM一言一概之"><a href="#SVM一言一概之" class="headerlink" title="SVM一言一概之"></a>SVM一言一概之</h1><p>基于结构风险最小化（最大化分类间隔$\frac{2}{|W|}$）提高机器学习泛化能力，实现经验风险和置信范围的最小化，从而在小样本的情况下获得较好的统计规律。</p>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>使用内积核函数代替高维空间的非线性映射，可解决非线性问题</li>
<li>小样本学习，无需依赖整个样本数据，因为其分类只取决于少数的支持向量，计算的复杂性与样本维数无关，所以某种程度上算是避免了维数灾难，在较高维度的文本分类中较为受欢迎</li>
<li>也正因为模型只与支持向量有关，所以对支持向量以外的样本操作不会改变模型，具有一定的鲁棒性</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>在求解核矩阵时，该矩阵维数为m阶(样本个数)，若样本很大，则核矩阵的计算和存储都很号位资源，故不使用与大样本</li>
<li>对缺失数据和异常点很敏感，因为本就是靠少量的支持向量完成分类，若缺失的数据和异常点可能与支持向量有关，则会对最终的模型产生很大的影响</li>
</ul>
<h2 id="核函数的选择"><a href="#核函数的选择" class="headerlink" title="核函数的选择"></a>核函数的选择</h2><p>核函数的选择是SVM最重要的参数之一，SVM主要有以下几种核函数：</p>
<ul>
<li>多项式核函数</li>
<li>高斯核函数：RBF核函数可以将输入空间映射至无穷空间内</li>
<li>线性核函数</li>
<li>sigmoid核函数</li>
<li>字符串核函数<br>线性一般选择线性核，效果还不错；非线性一般选择RBF核，不过调参需要使用Cross-Validation来选择。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/14/经典模型之Logostic-Regression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiayu Zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiayu | Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/14/经典模型之Logostic-Regression/" itemprop="url">经典模型之Logostic Regression</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-14T11:52:45+08:00">
                2018-09-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/经典模型/" itemprop="url" rel="index">
                    <span itemprop="name">经典模型</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>逻辑斯蒂回归真的是经典的不能再经典的机器学习模型了。正值找工作之际，按照模型-&gt;目标函数设计及求解的路线讲完模型后，还会加一些模型的特性，比如优缺点、和相似的模型相比下算法和应用场景的不同等。也可能加入一些面试题。</p>
<h1 id="LR模型"><a href="#LR模型" class="headerlink" title="LR模型"></a>LR模型</h1><h2 id="名称由来"><a href="#名称由来" class="headerlink" title="名称由来"></a>名称由来</h2><p>虽然名字里有regression，但实际上逻辑回归是一个分类算法，既然是分类，为何又叫分类呢？据考究是高尔顿研究父母及其子女身高时，返现整体人类的身高会回归到一个均线上，便在讨论中将回归一词引入，后面大家讨论线性回归时也就沿用了。逻辑回归其实是由线性回归得来（后面可以看到），故便称为逻辑回归。</p>
<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>首先介绍线性回归，后面再介绍逻辑回归时会从此处引出。</p>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>线性回归是一个回归方法，其表达式为：$$y = w^T * x + b \tag{1}$$<br>其中，w和b为模型参数。当x时多维时，便为多元线性回归。</p>
<h3 id="目标函数设计"><a href="#目标函数设计" class="headerlink" title="目标函数设计"></a>目标函数设计</h3><p>线性回归的目标函数为回归值与真实值平方差之和：$$Obj(\theta) = \frac{1}{2} \sum(y-\hat{y})^2 \tag{2}$$<br>可以通过惩罚与真实值相差较大的回归值使得此目标函数最小，从而得到最优参数。</p>
<h3 id="目标函数求解"><a href="#目标函数求解" class="headerlink" title="目标函数求解"></a>目标函数求解</h3><p>目标函数求解有两种方法：最小二乘法、梯度下降法，前者可以获得解析解，后者一般是设置阈值以获得近似解。</p>
<h4 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h4><p>最小二乘法求解目标函数有两种求解方式，一种是非矩阵形式求解(一元)，另一种则是以矩阵形式求解（多元）</p>
<h5 id="非矩阵形式最小二乘法"><a href="#非矩阵形式最小二乘法" class="headerlink" title="非矩阵形式最小二乘法"></a>非矩阵形式最小二乘法</h5><p>由式1可得：<br><img src="https://ws3.sinaimg.cn/large/006tNbRwly1fv9egmzh19j30xi0aadgt.jpg" alt=""><br>令上式为0，即可得到：<br>$$w = \frac{\sum_{i=1}^n x_i*y_i - \bar{y}\sum_{i=1}^nx_i}{\sum_{i=1}^n x_i^2 - \bar{x}\sum_{i=1}^nx_i}\tag{5}$$<br>$$b = \bar{y} - w\bar{x} \tag{6}$$</p>
<h5 id="矩阵形式求解最小二乘法"><a href="#矩阵形式求解最小二乘法" class="headerlink" title="矩阵形式求解最小二乘法"></a>矩阵形式求解最小二乘法</h5><p>易知若要使得Obj最小，目的肯定是使得$X*W = Y$，由此即可得$$W = (X^TX)^{-1}X^TY\tag{7}$$。<br>当然也可以用梯度来计算：<br>$$obj = (Y-W^TX)^T(Y-W^TX)$$</p>
<h4 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h4><p>梯度下降法和前面原理类似，不同的是它随机给参数赋值，之后用梯度来更新参数，直至小于等于给定的阈值。</p>
<h2 id="Logistic-regression"><a href="#Logistic-regression" class="headerlink" title="Logistic regression"></a>Logistic regression</h2><h3 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h3><p>针对上述的线性回归，若将输出经过非线性激活函数sigmoid，则可得：<br>$$y = sigmoid(wx+b) = \frac{1}{1+e^{-(wx+b)}}\tag{11}$$<br>从而可将y映射到（0，1）区间。<br>换一种方式再来看Logistic Regression，定义p/(1-p)为几率，则可得：<br>$$\log\frac{p}{1-p} = wx+b \tag{12}$$<br>直观解释就是逻辑斯蒂回归本质上是使用线性回归来拟合对数几率。</p>
<h3 id="损失函数设计及求解"><a href="#损失函数设计及求解" class="headerlink" title="损失函数设计及求解"></a>损失函数设计及求解</h3><p>逻辑斯蒂回归的损失函数很有意思，是交叉熵，由最大化后验概率推导而来。<br>$$cross_entropy = \sum_{i=1}^nP\log{P} \tag{13}$$</p>
<h3 id="优点及缺点"><a href="#优点及缺点" class="headerlink" title="优点及缺点"></a>优点及缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li>直接对分类可能性进行建模，无需事先假设数据分布，避免了假设分布不准确所带来的问题</li>
<li>计算时计算量较小，速度快，存储资源占用少</li>
<li>输出的决策是类别，但是以概率的形式，对需要利用概率辅助决策的任务很有用</li>
<li>对数几率函数（这里的sigmoid函数）是凸函数，现有的许多数值优化算法都可直接用于求取最优解</li>
<li>形式简单，可解释性好</li>
<li>对观测样本的概率输出可设置不容的阈值进行截断，对分类不平衡样本也算一个超参数</li>
<li>相比于线性回归来说，因为经过了一个非线性映射，将距离分类平面较远的点的权重进行了压缩，相当于每个点的权重都一样，不因距离分类平面的远近而有所改变。线性回归则是距离平面越远，样本权重越高；SVM则是更为极端，将不在分类间隔平面上的点的权重皆设为0。</li>
</ul>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>对于非线性数据需要进行数值转换</li>
<li>预设的是数据必须线性可分</li>
<li>对多重共线性较为敏感，原因是因为当存在多重共线性时，解析解W中的组元$X^TX$不满秩，从而会使W方差大，从而过拟合，使用正则化方法则可以解决这个问题。</li>
<li>容易欠拟合，分类精度不高</li>
<li>不能处理缺失值，需要进行一些填充处理</li>
<li>对异常点敏感，但比线性回归好得多，因为只会造成与正确样本同权重的影响，而不是像线性回归那样距离分类平面越远造成影响越大</li>
</ul>
<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>关于logistic回归的变量筛选方法，有较为常见的三种：</p>
<ul>
<li>向前引入法</li>
<li>向后剔除法</li>
<li>逐步回归法</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/13/Named-Entity-Recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiayu Zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiayu | Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/13/Named-Entity-Recognition/" itemprop="url">Named Entity Recognition</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-13T01:18:03+08:00">
                2018-09-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>命名实体识别是NLP的“hello world”，不过这个“你好”还是需要一些技巧才能说得“state of art”。以下介绍经典的命名实体算法，包括传统的基于特征模板的方法和近来兴起的深度学习方法。</p>
<h1 id="NER之传统特征模板算法"><a href="#NER之传统特征模板算法" class="headerlink" title="NER之传统特征模板算法"></a>NER之传统特征模板算法</h1><p>在深度学习未兴起之前，工程师们用的主要是词典和规则，再然后是传统的机器学习，如线性统计模型，如隐马尔科夫模型(HMM)、最大熵马尔可夫模型(MEMM)以及条件随机场模型(CRF)。这里先简要介绍一下马尔可夫模型的原理，再主要介绍一下条件随机场模型用于标注的原理及场景。</p>
<h2 id="HMM简介"><a href="#HMM简介" class="headerlink" title="HMM简介"></a>HMM简介</h2><p>隐马尔科夫模型是一个关于时序的概率模型，描述的是一个隐藏的马尔科夫链随机生成一个随机的状态序列，然后再由该状态序列随机生成随机观测序列的过程。<br>一个HMM模型可以用$(\pi, A, B)$来表示，其中</p>
<ul>
<li>$\pi$代表初始状态概率向量，描述的是生成某个初始状态的概率</li>
<li>$A$表示状态转移概率矩阵，描述的是有一个状态转移到另一个状态的概率</li>
<li>$B$表示观测概率矩阵，描述的是由某个状态生成某个观测的概率</li>
</ul>
<p>由此可以得到HMM衍生出的三个问题：</p>
<ul>
<li>概率计算问题：预测在给定模型用$(\pi, A, B)$下某个观测序列出现的概率，一般是前向后向算法</li>
<li>学习问题：给定某个观测序列，求使得观测序列出现概率最大的模型参数用$(\pi, A, B)$，一般是使用最大似然法求解</li>
<li>预测/解码问题：给定观测序列和模型用$(\pi, A, B)$，预测概率最大的状态序列（标注问题中，观测序列是句子，状态序列是标注）</li>
</ul>
<h2 id="CRF简介"><a href="#CRF简介" class="headerlink" title="CRF简介"></a>CRF简介</h2><h3 id="CRF定义"><a href="#CRF定义" class="headerlink" title="CRF定义"></a>CRF定义</h3><p>若要说到CRF定义，就需要预定义很多变量：</p>
<ul>
<li>概率无向图：联合分布概率$P(Y)$，可由无向图用$G(V,E)$表示，其中V表示节点，代表一个随机变量，E表示边，代表随机变量之间的概率关系。若联合概率$P(Y)$满足成对马尔科夫性、局部马尔科夫性或全局马尔科夫性，就称此联合分布概率为概率无向图模型或马尔科夫随机场</li>
<li>最大团:无向图中任意两个节点皆有边连接的子集称为团，最大的子集称为最大团</li>
<li>因子分解：将概率无向图模型的联合分布概率表示为其最大团上随机变量的函数的乘积形式的操作，称为概率无向图模型的因子分解，即：$$P(Y) = \frac{1}{Z} \prod_C \Psi_c(Y_C) \tag{1}$$<br>其中$$Z = \sum_Y  \prod_C \Psi_c(Y_C) \tag{2}$$<br>$\Psi_C(Y_C)$为势函数，要求势函数为严格正的，一般为指数函数</li>
</ul>
<p>那么便可得到CRF的定义：<strong>给定随机变量X条件下，随机变量Y的条件随机场即为条件随机场</strong>。这里主要介绍定义在线性链上的特殊的条件随机场，称为线性链条件随机场，此随机场便可用于标注问题。用于标注问题时，X是待标注序列，对应HMM中的观测序列；Y是标注序列，对应于HMM中的状态序列。训练时利用数据集通过极大似然估计（可带正则）得到条件概率模型$P(\hat{Y}|X)$；预测时，对于给定的输入序列x，求出条件概率$P(\hat{y}|x)$最大的输出序列$\hat{y}$。<br>现实中一般设X和Y具有相同的图结构，以下是线性链条件随机场结构图：</p>
<p><center><img src="https://ws3.sinaimg.cn/large/006tNbRwly1fv7qt84cdgj30b40693ye.jpg" alt=""></center></p>
<p><center>图1 线性链条件随机场</center><br>则可得</p>
<ul>
<li>线性链条件随机场的定义为：设$X = (X_1,X_2,…X_n), Y = (Y_1, Y_2,…Y_n)$均为线性链表示的随机变量序列，若在给定随机变量序列X的条件下，随机变量Y的条件概率$P(Y|X)$构成条件随机场，即满足马尔科夫性：$$P(Y_i|X,Y_1…Y_{i-1},Y_{i+1},…Y_n) = P(Y_i|X,Y_{i-1},Y_{i+1})\tag{3}$$<br>则称$P(Y|X)$为线性链条件随机场。在标注问题中，X表示输入观测序列，Y表示输出标记序列或状态序列。</li>
</ul>
<h3 id="CRF参数模型"><a href="#CRF参数模型" class="headerlink" title="CRF参数模型"></a>CRF参数模型</h3><p>条件随机场的参数化形式为：<br>$$P(y|x) = \frac{1}{Z}exp(\sum_{i,k}\lambda_kt_k(x,y_{i-1},y_i,i)+\sum_{l,k}\mu_ls_l(x,y_i,i))\tag{4}$$<br>其中，函数t为定义在边上的特征函数，为转移特征，$\lambda_k$为其权重；函数s为定义在顶点上的特征函数，为状态特征，$\mu_l$为其权重。k、l分别为其个数。CRF完全由特征函数和权重确定，一般来说满足特征条件时特征函数取值为1，否则为0。也由此可以看出CRF也是对数线性模型。</p>
<h3 id="CRF预测算法"><a href="#CRF预测算法" class="headerlink" title="CRF预测算法"></a>CRF预测算法</h3><p>针对条件随机场，也有与HMM相同的相应的三个问题，这里主要数一下预测问题。<br>预测问题是给定条件随机场$P{Y|X}$和输入序列（观测序列）x，求条件概率最大的输出序列（状态序列）$y^*$，即对观测序列进行标注，解决方法是著名的维特比算法。<br>维特比算法的原理本质上就是动态规划。假设每个状态有三种可能，要输出10个状态，最暴力的方法是计算$3^{10}$个概率后取最大的概率所对应的路径，而动态规划的思想是每次都取上一个最大的概率，那么就相当于每个状态需要计算$3^2$次，最终的复杂度为$O(3*3*10)$，大大缩减了复杂度。<br>关于维特比算法的例子写得比较容易理解的在<a href="https://www.zhihu.com/question/20136144" target="_blank" rel="noopener">知乎这里</a>。</p>
<h1 id="NER之深度学习版"><a href="#NER之深度学习版" class="headerlink" title="NER之深度学习版"></a>NER之深度学习版</h1><p>深度学习在NLP里的应用一发不可收拾，尤其是LSTM。这里首先介绍最为经典的模型：Bi_LSTM+CRF模型。</p>
<h2 id="Bi-LSTM简介"><a href="#Bi-LSTM简介" class="headerlink" title="Bi-LSTM简介"></a>Bi-LSTM简介</h2><p>在<a href="https://jiayustar.net/2018/08/18/RNNs/" target="_blank" rel="noopener">RNNs</a>里介绍过。</p>
<h2 id="Bi-LSTM-CRF结构详解"><a href="#Bi-LSTM-CRF结构详解" class="headerlink" title="Bi-LSTM+CRF结构详解"></a>Bi-LSTM+CRF结构详解</h2><p>下图是Bi-LSTM+CRF结构图：<br><img src="https://github.com/Determined22/zh-NER-TF/raw/master/pics/pic1.png" alt=""></p>
<p><center>图2 Bi-LSTM+CRF结构</center><br>以下按照结构层次逐一介绍Bi-LSTM+CRF用于NER的过程。</p>
<h3 id="One-Hot-Vector层"><a href="#One-Hot-Vector层" class="headerlink" title="One Hot Vector层"></a>One Hot Vector层</h3><p>根据词库编号可以为每个词分配一个one hot向量</p>
<h3 id="Lookup层"><a href="#Lookup层" class="headerlink" title="Lookup层"></a>Lookup层</h3><p>Lookup层是深度学习应用于NLP的前提，它将一个个具象化的词或字符转化为具有数学内涵的固定维度的向量，然后作为样本输入至神经网络训练、学习。<br>Lookup层的词向量有三种。</p>
<ul>
<li>随机初始化</li>
<li>预训练词向量</li>
<li>预训练词向量+训练的字符向量（二者拼接）</li>
</ul>
<h3 id="Bi-LSTM层"><a href="#Bi-LSTM层" class="headerlink" title="Bi-LSTM层"></a>Bi-LSTM层</h3><p>这一层利用了双向RNN可以获取样本前后信息来帮助得到当前某个神经单元输出的特性，输出的隐层单元为前向后向的隐层输出拼接而成，然后经过输出层得到整个Bi-LSTM的输出。</p>
<h3 id="CRF层"><a href="#CRF层" class="headerlink" title="CRF层"></a>CRF层</h3><p>这一层主要是学习了一个概率转移矩阵A[k+2,k+2]，这样的话在打分时由x得到y的分数则由两部分组成（从隐层的单个神经元输出看）：</p>
<ul>
<li>单个神经元输出的向量为k维向量，其中k为标签的个数，每一维代表标记为某个标签的可能性大小，也是打分的一个要素</li>
<li>另一个打分要素则是标签转移概率，从矩阵A中得来<br>其实这一层结束后还有一个softmax操作，将最终的k个概率归一化。</li>
</ul>
<p>这些就是NER一些经典算法的流程原理了，有些仓促，日后有空再好好整理。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://www.cnblogs.com/Determined22/p/7238342.html" target="_blank" rel="noopener">Determined22的博客</a></li>
<li><a href="https://guillaumegenthial.github.io/sequence-tagging-with-tensorflow.html" target="_blank" rel="noopener">Guillaume Genthial blog</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Jiayu Zhang</p>
              <p class="site-description motion-element" itemprop="description">生如逆旅 不止行人</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">38</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jiayu Zhang</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
